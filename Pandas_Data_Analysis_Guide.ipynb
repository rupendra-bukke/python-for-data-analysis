{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af266c28",
   "metadata": {},
   "source": [
    "# Pandas Learning Guide: Data Analysis Fundamentals\n",
    "\n",
    "## Overview\n",
    "This notebook covers Pandas library from basics to advanced data analysis techniques. Pandas is essential for data manipulation, cleaning, and analysis.\n",
    "\n",
    "**What is Pandas?**\n",
    "- Python library for data manipulation and analysis\n",
    "- Built on NumPy\n",
    "- Provides data structures: Series and DataFrame\n",
    "- Handles missing data, data alignment, reshaping\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b9a2b",
   "metadata": {},
   "source": [
    "# Part 1: Installation and Setup\n",
    "\n",
    "## Installation\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn\n",
    "```\n",
    "\n",
    "## Import Pandas\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display version\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077eb88",
   "metadata": {},
   "source": [
    "# Part 2: Pandas Series\n",
    "\n",
    "## What is a Series?\n",
    "- 1-dimensional labeled array\n",
    "- Similar to Python list but with labels (index)\n",
    "- Can contain any data type\n",
    "- Built on NumPy arrays\n",
    "\n",
    "## Key Characteristics\n",
    "- **Index**: Labels for each element\n",
    "- **Values**: The actual data\n",
    "- **dtype**: Data type of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating Series\n",
    "\n",
    "# From list\n",
    "s1 = pd.Series([10, 20, 30, 40, 50])\n",
    "print(\"Series from list:\")\n",
    "print(s1)\n",
    "print(f\"Index: {s1.index.tolist()}\")\n",
    "print(f\"Values: {s1.values.tolist()}\")\n",
    "\n",
    "# With custom index\n",
    "s2 = pd.Series([90, 85, 88, 92, 78], index=['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'])\n",
    "print(\"\\nSeries with custom index (Student Grades):\")\n",
    "print(s2)\n",
    "\n",
    "# From dictionary\n",
    "s3 = pd.Series({'A': 100, 'B': 200, 'C': 300})\n",
    "print(\"\\nSeries from dictionary:\")\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152300f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing Series elements\n",
    "\n",
    "s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# By index\n",
    "print(f\"Element at index 'c': {s['c']}\")\n",
    "print(f\"First element: {s[0]}\")\n",
    "\n",
    "# Slicing\n",
    "print(f\"\\nSlice [0:3]: {s[0:3].tolist()}\")\n",
    "print(f\"Slice ['a':'c']: {s['a':'c'].tolist()}\")\n",
    "\n",
    "# Boolean indexing\n",
    "print(f\"\\nElements > 25: {s[s > 25].tolist()}\")\n",
    "\n",
    "# Series operations\n",
    "print(f\"\\nSum: {s.sum()}\")\n",
    "print(f\"Mean: {s.mean()}\")\n",
    "print(f\"Max: {s.max()}\")\n",
    "print(f\"Describe: \\n{s.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f44b40",
   "metadata": {},
   "source": [
    "# Part 3: Pandas DataFrame\n",
    "\n",
    "## What is a DataFrame?\n",
    "- 2-dimensional labeled data structure (like Excel table)\n",
    "- Rows and columns with labels\n",
    "- Can have different data types in each column\n",
    "- Most used Pandas data structure\n",
    "\n",
    "## Key Components\n",
    "- **Rows**: Indexed by row labels\n",
    "- **Columns**: Named columns\n",
    "- **Index**: Row labels\n",
    "- **Columns**: Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating DataFrames\n",
    "\n",
    "# From dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [25, 30, 28, 35, 22],\n",
    "    'Salary': [50000, 60000, 55000, 75000, 48000],\n",
    "    'Department': ['HR', 'IT', 'Finance', 'IT', 'HR']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Dtypes:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9242bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing DataFrame elements\n",
    "\n",
    "# Access column\n",
    "print(\"Access column 'Name':\")\n",
    "print(df['Name'].tolist())\n",
    "\n",
    "# Access multiple columns\n",
    "print(\"\\nAccess columns ['Name', 'Salary']:\")\n",
    "print(df[['Name', 'Salary']])\n",
    "\n",
    "# Access row by index\n",
    "print(\"\\nAccess row at index 0:\")\n",
    "print(df.loc[0])\n",
    "\n",
    "# Access by location (integer)\n",
    "print(\"\\nAccess by iloc (first 3 rows):\")\n",
    "print(df.iloc[0:3])\n",
    "\n",
    "# Access specific cell\n",
    "print(f\"\\nCell at row 1, column 'Name': {df.loc[1, 'Name']}\")\n",
    "print(f\"Cell at row 2, column 2 (iloc): {df.iloc[2, 2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33789b",
   "metadata": {},
   "source": [
    "# Part 4: Data Loading and Inspection\n",
    "\n",
    "## Loading Data\n",
    "- `pd.read_csv()`: Read CSV files\n",
    "- `pd.read_excel()`: Read Excel files\n",
    "- `pd.read_json()`: Read JSON files\n",
    "- `pd.read_sql()`: Read from SQL database\n",
    "- `pd.read_html()`: Read HTML tables\n",
    "\n",
    "## Inspecting Data\n",
    "- `head()`, `tail()`: First/last rows\n",
    "- `info()`: Data info and dtypes\n",
    "- `describe()`: Statistical summary\n",
    "- `shape()`: Dimensions\n",
    "- `dtypes`: Data types\n",
    "- `isnull()`: Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04313d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Data Inspection\n",
    "\n",
    "# First few rows\n",
    "print(\"First 3 rows:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# Last few rows\n",
    "print(\"\\nLast 2 rows:\")\n",
    "print(df.tail(2))\n",
    "\n",
    "# DataFrame info\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e36aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Missing values\n",
    "\n",
    "# Create DataFrame with missing values\n",
    "data_with_na = {\n",
    "    'Name': ['Alice', 'Bob', None, 'Diana', 'Eve'],\n",
    "    'Age': [25, None, 28, 35, 22],\n",
    "    'Salary': [50000, 60000, 55000, None, 48000]\n",
    "}\n",
    "\n",
    "df_na = pd.DataFrame(data_with_na)\n",
    "print(\"DataFrame with missing values:\")\n",
    "print(df_na)\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nNull values count:\")\n",
    "print(df_na.isnull().sum())\n",
    "\n",
    "# Check for non-null values\n",
    "print(\"\\nNon-null values count:\")\n",
    "print(df_na.notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e71615",
   "metadata": {},
   "source": [
    "# Part 5: Data Cleaning\n",
    "\n",
    "## Handling Missing Data\n",
    "- `dropna()`: Remove rows/columns with missing values\n",
    "- `fillna()`: Fill missing values\n",
    "- `isnull()`: Check for null values\n",
    "\n",
    "## Data Type Conversion\n",
    "- `astype()`: Convert data types\n",
    "- `pd.to_numeric()`: Convert to numeric\n",
    "- `pd.to_datetime()`: Convert to datetime\n",
    "\n",
    "## Handling Duplicates\n",
    "- `drop_duplicates()`: Remove duplicates\n",
    "- `duplicated()`: Identify duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Handling missing values\n",
    "\n",
    "df_clean = df_na.copy()\n",
    "\n",
    "# Drop rows with any null value\n",
    "print(\"After dropna():\")\n",
    "print(df_clean.dropna())\n",
    "\n",
    "# Fill missing values\n",
    "print(\"\\nAfter fillna(0):\")\n",
    "print(df_na.fillna(0))\n",
    "\n",
    "# Fill with forward fill (propagate last value)\n",
    "print(\"\\nAfter fillna(method='ffill'):\")\n",
    "print(df_na.fillna(method='ffill'))\n",
    "\n",
    "# Fill specific column\n",
    "print(\"\\nFill 'Age' with median:\")\n",
    "df_na['Age'].fillna(df_na['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Data type conversion\n",
    "\n",
    "df_type = pd.DataFrame({\n",
    "    'A': ['1', '2', '3', '4'],\n",
    "    'B': [1.5, 2.5, 3.5, 4.5],\n",
    "    'C': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04']\n",
    "})\n",
    "\n",
    "print(\"Original dtypes:\")\n",
    "print(df_type.dtypes)\n",
    "\n",
    "# Convert string to integer\n",
    "df_type['A'] = df_type['A'].astype(int)\n",
    "\n",
    "# Convert to datetime\n",
    "df_type['C'] = pd.to_datetime(df_type['C'])\n",
    "\n",
    "print(\"\\nAfter conversion:\")\n",
    "print(df_type.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84619b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Handling duplicates\n",
    "\n",
    "df_dup = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],\n",
    "    'Age': [25, 30, 25, 28, 30]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_dup)\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nDuplicated rows:\")\n",
    "print(df_dup.duplicated())\n",
    "\n",
    "# Drop duplicates\n",
    "print(\"\\nAfter drop_duplicates():\")\n",
    "print(df_dup.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c6927",
   "metadata": {},
   "source": [
    "# Part 6: Data Selection and Filtering\n",
    "\n",
    "## Selection Methods\n",
    "- `loc[]`: Label-based selection\n",
    "- `iloc[]`: Integer location-based selection\n",
    "- `at[]`, `iat[]`: Single value selection\n",
    "- `[]`: Column selection\n",
    "\n",
    "## Filtering\n",
    "- Boolean indexing\n",
    "- `isin()`: Check membership\n",
    "- `query()`: String-based filtering\n",
    "- `filter()`: Select columns by name pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filtering data\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Boolean indexing\n",
    "print(\"\\nEmployees with Age > 25:\")\n",
    "print(df[df['Age'] > 25])\n",
    "\n",
    "# Multiple conditions\n",
    "print(\"\\nEmployees in IT with Salary > 55000:\")\n",
    "print(df[(df['Department'] == 'IT') & (df['Salary'] > 55000)])\n",
    "\n",
    "# Using isin()\n",
    "print(\"\\nEmployees in HR or Finance:\")\n",
    "print(df[df['Department'].isin(['HR', 'Finance'])])\n",
    "\n",
    "# Using query()\n",
    "print(\"\\nUsing query():\")\n",
    "print(df.query('Age > 25 and Salary > 50000'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d42fc",
   "metadata": {},
   "source": [
    "# Part 7: Data Manipulation\n",
    "\n",
    "## Adding/Removing Columns\n",
    "- Add new column: `df['new_col'] = ...`\n",
    "- Drop column: `drop()`\n",
    "- Rename column: `rename()`\n",
    "\n",
    "## Transformations\n",
    "- `apply()`: Apply function to rows/columns\n",
    "- `map()`: Map values (Series only)\n",
    "- `str.methods()`: String operations\n",
    "- `astype()`: Change data type\n",
    "\n",
    "## Sorting\n",
    "- `sort_values()`: Sort by column values\n",
    "- `sort_index()`: Sort by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding and manipulating columns\n",
    "\n",
    "df_manip = df.copy()\n",
    "\n",
    "# Add new column\n",
    "df_manip['Bonus'] = df_manip['Salary'] * 0.1\n",
    "print(\"After adding Bonus column:\")\n",
    "print(df_manip)\n",
    "\n",
    "# Add calculated column\n",
    "df_manip['Salary_Category'] = df_manip['Salary'].apply(lambda x: 'High' if x > 60000 else 'Low')\n",
    "print(\"\\nAfter adding Salary_Category:\")\n",
    "print(df_manip)\n",
    "\n",
    "# Drop column\n",
    "df_manip = df_manip.drop('Bonus', axis=1)\n",
    "print(\"\\nAfter dropping Bonus column:\")\n",
    "print(df_manip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sorting data\n",
    "\n",
    "# Sort by single column\n",
    "print(\"Sorted by Age (ascending):\")\n",
    "print(df.sort_values('Age'))\n",
    "\n",
    "# Sort by multiple columns\n",
    "print(\"\\nSorted by Department, then Salary (descending):\")\n",
    "print(df.sort_values(['Department', 'Salary'], ascending=[True, False]))\n",
    "\n",
    "# Sort by index\n",
    "print(\"\\nSort by index:\")\n",
    "print(df.sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a053e",
   "metadata": {},
   "source": [
    "# Part 8: GroupBy and Aggregation\n",
    "\n",
    "## GroupBy\n",
    "- `groupby()`: Group by one or more columns\n",
    "- `agg()`: Apply aggregation functions\n",
    "- `transform()`: Apply function to group\n",
    "- `filter()`: Filter groups\n",
    "\n",
    "## Common Aggregations\n",
    "- `sum()`, `mean()`, `median()`, `std()`, `var()`\n",
    "- `min()`, `max()`, `count()`, `size()`\n",
    "- `first()`, `last()`\n",
    "- `describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: GroupBy operations\n",
    "\n",
    "# Group by single column\n",
    "print(\"Average salary by Department:\")\n",
    "print(df.groupby('Department')['Salary'].mean())\n",
    "\n",
    "# Multiple aggregations\n",
    "print(\"\\nDepartment statistics:\")\n",
    "print(df.groupby('Department')['Salary'].agg(['count', 'mean', 'min', 'max']))\n",
    "\n",
    "# Group by multiple columns\n",
    "df_multi = df.copy()\n",
    "df_multi['Seniority'] = ['Junior', 'Senior', 'Junior', 'Senior', 'Junior']\n",
    "print(\"\\nSalary by Department and Seniority:\")\n",
    "print(df_multi.groupby(['Department', 'Seniority'])['Salary'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Aggregation with multiple functions\n",
    "\n",
    "agg_dict = {\n",
    "    'Age': ['mean', 'min', 'max'],\n",
    "    'Salary': ['sum', 'mean'],\n",
    "    'Name': 'count'\n",
    "}\n",
    "\n",
    "print(\"Custom aggregations by Department:\")\n",
    "print(df.groupby('Department').agg(agg_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804433e",
   "metadata": {},
   "source": [
    "# Part 9: Merging and Joining\n",
    "\n",
    "## Merge Types\n",
    "- `pd.merge()`: SQL-like join\n",
    "- `join()`: Join on index\n",
    "- `concat()`: Concatenate DataFrames\n",
    "- `append()`: Add rows (deprecated, use concat)\n",
    "\n",
    "## Join Types\n",
    "- `inner`: Only matching rows\n",
    "- `left`: All rows from left DataFrame\n",
    "- `right`: All rows from right DataFrame\n",
    "- `outer`: All rows from both DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merging DataFrames\n",
    "\n",
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 5],\n",
    "    'Salary': [50000, 60000, 55000, 70000]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "# Inner merge (only matching)\n",
    "print(\"\\nInner merge:\")\n",
    "print(pd.merge(df1, df2, on='ID', how='inner'))\n",
    "\n",
    "# Left merge\n",
    "print(\"\\nLeft merge:\")\n",
    "print(pd.merge(df1, df2, on='ID', how='left'))\n",
    "\n",
    "# Outer merge\n",
    "print(\"\\nOuter merge:\")\n",
    "print(pd.merge(df1, df2, on='ID', how='outer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Concatenating DataFrames\n",
    "\n",
    "df_a = pd.DataFrame({\n",
    "    'A': [1, 2],\n",
    "    'B': [3, 4]\n",
    "})\n",
    "\n",
    "df_b = pd.DataFrame({\n",
    "    'A': [5, 6],\n",
    "    'B': [7, 8]\n",
    "})\n",
    "\n",
    "# Concatenate rows\n",
    "print(\"Concatenate rows (axis=0):\")\n",
    "print(pd.concat([df_a, df_b], ignore_index=True))\n",
    "\n",
    "# Concatenate columns\n",
    "print(\"\\nConcatenate columns (axis=1):\")\n",
    "print(pd.concat([df_a, df_b], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5665759",
   "metadata": {},
   "source": [
    "# Part 10: Time Series Analysis\n",
    "\n",
    "## DateTime Operations\n",
    "- `pd.to_datetime()`: Convert to datetime\n",
    "- `dt.accessor`: Access date/time components\n",
    "- `date_range()`: Create date range\n",
    "- `resample()`: Resample time series\n",
    "\n",
    "## Components\n",
    "- `dt.year`, `dt.month`, `dt.day`\n",
    "- `dt.hour`, `dt.minute`, `dt.second`\n",
    "- `dt.dayofweek`, `dt.week`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DateTime operations\n",
    "\n",
    "# Create date range\n",
    "dates = pd.date_range('2024-01-01', periods=5, freq='D')\n",
    "df_ts = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Sales': [100, 150, 120, 200, 180]\n",
    "})\n",
    "\n",
    "print(\"Time Series DataFrame:\")\n",
    "print(df_ts)\n",
    "\n",
    "# Extract date components\n",
    "df_ts['Year'] = df_ts['Date'].dt.year\n",
    "df_ts['Month'] = df_ts['Date'].dt.month\n",
    "df_ts['Day'] = df_ts['Date'].dt.day\n",
    "df_ts['DayOfWeek'] = df_ts['Date'].dt.day_name()\n",
    "\n",
    "print(\"\\nAfter extracting components:\")\n",
    "print(df_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefa53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Resampling time series\n",
    "\n",
    "# Create longer time series\n",
    "dates = pd.date_range('2024-01-01', periods=30, freq='D')\n",
    "df_resample = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Sales': np.random.randint(50, 200, 30)\n",
    "})\n",
    "\n",
    "# Set Date as index\n",
    "df_resample.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Daily Sales (first 5 rows):\")\n",
    "print(df_resample.head())\n",
    "\n",
    "# Resample to weekly average\n",
    "print(\"\\nWeekly average sales:\")\n",
    "print(df_resample.resample('W').mean())\n",
    "\n",
    "# Resample to monthly sum\n",
    "print(\"\\nMonthly total sales:\")\n",
    "print(df_resample.resample('M').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723c78f",
   "metadata": {},
   "source": [
    "# Part 11: Data Export\n",
    "\n",
    "## Export Formats\n",
    "- `to_csv()`: Export to CSV\n",
    "- `to_excel()`: Export to Excel\n",
    "- `to_json()`: Export to JSON\n",
    "- `to_sql()`: Export to SQL database\n",
    "- `to_html()`: Export to HTML\n",
    "- `to_pickle()`: Export to pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d48bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Exporting data\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv('employees.csv', index=False)\n",
    "print(\"Exported to CSV\")\n",
    "\n",
    "# Export to Excel\n",
    "# df.to_excel('employees.xlsx', index=False)\n",
    "# print(\"Exported to Excel\")\n",
    "\n",
    "# Export to JSON\n",
    "df.to_json('employees.json', orient='records')\n",
    "print(\"Exported to JSON\")\n",
    "\n",
    "# Read back from CSV\n",
    "df_read = pd.read_csv('employees.csv')\n",
    "print(\"\\nRead from CSV:\")\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c2c78",
   "metadata": {},
   "source": [
    "# Part 12: Practice Exercises\n",
    "\n",
    "## Exercise 1: Data Cleaning and Analysis\n",
    "Given a dataset with missing values, clean it and perform analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ccf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Data Cleaning\n",
    "\n",
    "# Create messy dataset\n",
    "messy_data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 5],\n",
    "    'Name': ['Alice', 'Bob', None, 'Diana', 'Eve', 'Eve'],\n",
    "    'Score': [85, None, 90, 88, 92, 92],\n",
    "    'Grade': ['A', 'B', 'A', None, 'A', 'A']\n",
    "}\n",
    "\n",
    "df_messy = pd.DataFrame(messy_data)\n",
    "print(\"Original messy data:\")\n",
    "print(df_messy)\n",
    "\n",
    "# Clean the data\n",
    "df_clean = df_messy.drop_duplicates()\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "print(\"\\nCleaned data:\")\n",
    "print(df_clean)\n",
    "\n",
    "# Analysis\n",
    "print(f\"\\nAverage Score: {df_clean['Score'].mean():.2f}\")\n",
    "print(f\"Grade distribution:\\n{df_clean['Grade'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15b0f1",
   "metadata": {},
   "source": [
    "## Exercise 2: Filtering and Transformation\n",
    "Filter specific data and create new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf226c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Filtering and Transformation\n",
    "\n",
    "# Create sample sales data\n",
    "sales_data = {\n",
    "    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A'],\n",
    "    'Quantity': [10, 5, 8, 15, 3, 12, 7],\n",
    "    'Price': [100, 200, 150, 100, 200, 150, 100]\n",
    "}\n",
    "\n",
    "df_sales = pd.DataFrame(sales_data)\n",
    "\n",
    "# Add new columns\n",
    "df_sales['Total_Sales'] = df_sales['Quantity'] * df_sales['Price']\n",
    "df_sales['Category'] = df_sales['Total_Sales'].apply(lambda x: 'High' if x > 1000 else 'Low')\n",
    "\n",
    "print(\"Sales data with new columns:\")\n",
    "print(df_sales)\n",
    "\n",
    "# Filter high-value sales\n",
    "high_sales = df_sales[df_sales['Category'] == 'High']\n",
    "print(\"\\nHigh-value sales:\")\n",
    "print(high_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac5121",
   "metadata": {},
   "source": [
    "## Exercise 3: GroupBy Analysis\n",
    "Analyze data by groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: GroupBy Analysis\n",
    "\n",
    "# Summary by product\n",
    "print(\"Sales summary by product:\")\n",
    "summary = df_sales.groupby('Product').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'Price': 'first',\n",
    "    'Total_Sales': ['sum', 'mean']\n",
    "})\n",
    "print(summary)\n",
    "\n",
    "# Product with highest average sale\n",
    "avg_by_product = df_sales.groupby('Product')['Total_Sales'].mean()\n",
    "top_product = avg_by_product.idxmax()\n",
    "print(f\"\\nProduct with highest average sale: {top_product} (${avg_by_product[top_product]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78172632",
   "metadata": {},
   "source": [
    "## Exercise 4: Merging Datasets\n",
    "Merge two related datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Merging datasets\n",
    "\n",
    "# Create customer and order data\n",
    "customers = pd.DataFrame({\n",
    "    'CustomerID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'OrderID': [101, 102, 103, 104, 105],\n",
    "    'CustomerID': [1, 2, 1, 3, 2],\n",
    "    'Amount': [500, 300, 250, 400, 350]\n",
    "})\n",
    "\n",
    "print(\"Customers:\")\n",
    "print(customers)\n",
    "print(\"\\nOrders:\")\n",
    "print(orders)\n",
    "\n",
    "# Merge\n",
    "merged = pd.merge(customers, orders, on='CustomerID', how='left')\n",
    "print(\"\\nMerged data:\")\n",
    "print(merged)\n",
    "\n",
    "# Analysis: Total amount by customer\n",
    "print(\"\\nTotal amount by customer:\")\n",
    "print(merged.groupby('Name')['Amount'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11881da",
   "metadata": {},
   "source": [
    "## Exercise 5: Time Series Aggregation\n",
    "Aggregate time series data by periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Time Series Analysis\n",
    "\n",
    "# Create daily sales data\n",
    "dates = pd.date_range('2024-01-01', periods=30, freq='D')\n",
    "ts_sales = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Sales': np.random.randint(100, 500, 30)\n",
    "})\n",
    "\n",
    "ts_sales.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Daily sales (first 5 rows):\")\n",
    "print(ts_sales.head())\n",
    "\n",
    "# Weekly aggregation\n",
    "weekly_sales = ts_sales.resample('W').agg({'Sales': ['sum', 'mean', 'max']})\n",
    "print(\"\\nWeekly sales summary:\")\n",
    "print(weekly_sales)\n",
    "\n",
    "# Total monthly sales\n",
    "print(\"\\nTotal monthly sales:\")\n",
    "print(ts_sales.resample('M').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb5dac",
   "metadata": {},
   "source": [
    "# Key Pandas Concepts Summary\n",
    "\n",
    "## Data Structures\n",
    "1. **Series**: 1D labeled array (like list with index)\n",
    "2. **DataFrame**: 2D labeled table (like Excel sheet)\n",
    "\n",
    "## Key Operations\n",
    "| Operation | Method | Example |\n",
    "|-----------|--------|----------|\n",
    "| Load data | `pd.read_csv()` | Read from file |\n",
    "| View data | `head()`, `tail()` | See first/last rows |\n",
    "| Inspect | `info()`, `describe()` | Get data info/stats |\n",
    "| Clean | `dropna()`, `fillna()` | Handle missing values |\n",
    "| Filter | `df[condition]` | Select rows |\n",
    "| Select | `loc[]`, `iloc[]` | Access by label/position |\n",
    "| Sort | `sort_values()` | Arrange data |\n",
    "| Group | `groupby()` | Aggregate by groups |\n",
    "| Merge | `merge()`, `join()` | Combine datasets |\n",
    "| Export | `to_csv()` | Save to file |\n",
    "\n",
    "## Analysis Workflow\n",
    "1. **Load**: Import data from various sources\n",
    "2. **Explore**: Understand data structure and content\n",
    "3. **Clean**: Handle missing values and duplicates\n",
    "4. **Transform**: Create new columns and prepare data\n",
    "5. **Analyze**: GroupBy, aggregations, statistical analysis\n",
    "6. **Visualize**: Create charts and plots\n",
    "7. **Export**: Save results\n",
    "\n",
    "## Best Practices\n",
    "- Always check data types and missing values first\n",
    "- Use `copy()` to avoid modifying original data\n",
    "- Use `inplace=True` carefully (modifies original)\n",
    "- Validate data after transformations\n",
    "- Use meaningful column names\n",
    "- Document your data cleaning steps\n",
    "- Test code on sample data first\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Data Analysis! ðŸ“Š**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
